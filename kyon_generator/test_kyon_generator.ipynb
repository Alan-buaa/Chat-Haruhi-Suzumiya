{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Chat-Haruhi-Suzumiya/blob/main/kyon_generator/test_kyon_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat凉宫春日 Chat-Haruhi-Suzumiya\n",
        "\n",
        "[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)]()\n",
        "[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)]()\n",
        "[![Huggingface Gradio](https://img.shields.io/static/v1?label=Demo&message=Huggingface%20Gradio&color=orange)](https://huggingface.co/spaces/silk-road/ChatHaruhi)\n",
        "\n",
        "\n",
        "本脚本是李鲁鲁开发的KyonGenerator的测试工具，后者由\n",
        "\n",
        "李鲁鲁，闫晨曦, 包同学, 睡觉鱼等共同开发\n",
        "\n",
        "---\n",
        "\n",
        "**Chat凉宫春日**是模仿凉宫春日等一系列动漫人物，使用近似语气、个性和剧情聊天的语言模型，\n",
        "\n",
        "<details>\n",
        "  <summary> 本项目由李鲁鲁，冷子昂，闫晨曦，封小洋，scixing，沈骏一，Aria Fei, 米唯实, 吴平宇, 贾曜恺等开发。 </summary>\n",
        "\n",
        "李鲁鲁发起了项目，并完成了最早的版本，在多个微信群实现了测试。完成了训练数据自动生成对话部分，设计了整体的路线，并撰写报告。\n",
        "\n",
        "冷子昂负责了每一个阶段的Gradio开发，以及每个部分的功能整合和架构设计。\n",
        "\n",
        "闫晨曦一开始将李鲁鲁的notebook重构为app.py，参与了WebUI的embedding部分重构整合。\n",
        "\n",
        "封小洋进行了中文转日文模型的选型，完成了针对台词抽取图片的工具。整合了声纹识别。即将继续参加台本工具的开发。\n",
        "\n",
        "scixing实践了VITS语音，完成了台词对应的语音抽取，实现了第一个版本的声纹分类。\n",
        "\n",
        "沈骏一实现了使用ChatGLM2 finetune实验\n",
        "\n",
        "Aria(Yaying Fei)对接了whisper到台本工具。即将继续参加台本工具的开发。\n",
        "\n",
        "米唯实实现了Chat哆啦A梦的分支版本\n",
        "\n",
        "吴平宇部署了ChatGLM2的训练程序，并提供了训练的计算资源。\n",
        "\n",
        "贾曜恺开发了一个Vue前端实现方案\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "xQqfMSu5FwUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LC1332/Chat-Haruhi-Suzumiya"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iATX-_amFs0n",
        "outputId": "56bac750-227d-4453-ae90-86a42f5a67e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Chat-Haruhi-Suzumiya'...\n",
            "remote: Enumerating objects: 13008, done.\u001b[K\n",
            "remote: Counting objects: 100% (3126/3126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2971/2971), done.\u001b[K\n",
            "remote: Total 13008 (delta 167), reused 3040 (delta 138), pack-reused 9882\u001b[K\n",
            "Receiving objects: 100% (13008/13008), 158.66 MiB | 14.48 MiB/s, done.\n",
            "Resolving deltas: 100% (2137/2137), done.\n",
            "Updating files: 100% (8214/8214), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SytUs-oI4Hd",
        "outputId": "afc9e8f3-9d82-450d-f299-10c9a313ec9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tiktoken transformers jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9ykx-hICe8l",
        "outputId": "82d3392b-ce49-478b-a6bf-ba0835468906"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWCXGjG-FJdq",
        "outputId": "23ee223c-a1c2-4302-91ac-c1e9a0f2ad36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Chat-Haruhi-Suzumiya/kyon_generator\n",
            "chat2dialogue.py\t   generate_character.py\n",
            "ChatGPT_for_generation.py  story2chat.py\n",
            "chatlog2dialogue.ipynb\t   synthesis_chat_method_foo.py\n",
            "chatlog2dialogue.py\t   synthesis_chat.py\n",
            "data\t\t\t   test_kyon_generator.ipynb\n",
            "dialogue2chat.py\t   train.py\n",
            "dialogue2embedding.py\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Chat-Haruhi-Suzumiya/kyon_generator/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZVbJHRUGhTK",
        "outputId": "ab6d2108-98be-46e2-f1ae-c0fd90bca0f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Haruhi-ContinuousGenerate_Dialogues.jsonl  test_query_chat_Hermione.jsonl\n",
            "Haruhi_first_merge_res.jsonl\t\t   test_query_chat_liyunlong.jsonl\n",
            "Haruhi-Lulu_Dialogues.jsonl\t\t   test_query_chat_Malfoy.jsonl\n",
            "test_query_chat_Haruhi.jsonl\t\t   test_query_chat_weixiaobao.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output"
      ],
      "metadata": {
        "id": "nTgRVhgcG39G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gradio前端记录的历史数据到dialogue数据\n",
        "chatlog2dialogue.py gradio前端记录的历史数据到dialogue数据的转化\n",
        "\n"
      ],
      "metadata": {
        "id": "QkKog1XUGdEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python chatlog2dialogue.py -input ./data/Haruhi-Lulu_Dialogues.jsonl\\\n",
        "                           -output ./output/Haruhi_Dialogues_from_history.jsonl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZmmLHFGGUgZ",
        "outputId": "55cab0a3-0fdc-4a84-fcc3-12bab4930727"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "未实现"
      ],
      "metadata": {
        "id": "En_FJ9gtl0V9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## story2chat 台本数据到一句话数据的转换\n",
        "\n",
        "Haruhi为例的话语料在\n",
        "\n",
        "/content/Chat-Haruhi-Suzumiya/characters/haruhi/texts"
      ],
      "metadata": {
        "id": "rTAg037YHTf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python story2chat.py -story_folder \"/content/Chat-Haruhi-Suzumiya/characters/haruhi/texts\" \\\n",
        "                     -output ./output/chat_from_story.jsonl \\\n",
        "                     -role \"春日\" \\\n",
        "                     -other_names 凉宫 凉宫春日"
      ],
      "metadata": {
        "id": "tJq8CswXHMar"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python story2chat.py -story_folder \"/content/Chat-Haruhi-Suzumiya/characters/weixiaobao/texts\" \\\n",
        "                     -output ./output/chat_from_story_weixiaobao.jsonl \\\n",
        "                     -role \"韦小宝\" \\\n",
        "                     -other_names 小宝"
      ],
      "metadata": {
        "id": "qxQqcl2tmAaQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python story2chat.py -story_folder \"/content/Chat-Haruhi-Suzumiya/characters/Hermione/texts\" \\\n",
        "                     -output ./output/chat_from_story_Hermione.jsonl \\\n",
        "                     -role \"Hermione\""
      ],
      "metadata": {
        "id": "tRu8EQiJmjch"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试通过 implemented by 冷月"
      ],
      "metadata": {
        "id": "Ykw3uZLzmyxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dialogue2chat 将连续对话批量抽取为一句话"
      ],
      "metadata": {
        "id": "fkuR83edH7am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python dialogue2chat.py -input ./data/Haruhi-Lulu_Dialogues.jsonl\\\n",
        "                     -output ./output/chat_from_dialogue.jsonl\\\n",
        "                     -role \"春日\"\\\n",
        "                     -other_names 凉宫 凉宫春日"
      ],
      "metadata": {
        "id": "zwZgBFPxH8dE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试通过"
      ],
      "metadata": {
        "id": "bRmSkEmAm5tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## synthesis_chats 将一些第一句话的文件，增广为更多的第一句话"
      ],
      "metadata": {
        "id": "y6ykfthzIfOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里需要设置OpenAI Key"
      ],
      "metadata": {
        "id": "MZApS5ubJE-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-Z2fFpp\""
      ],
      "metadata": {
        "id": "o7oDiePZJfwe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: 这里Haruhi_first_merge_res.jsonl本来就是synthesized的，\n",
        "\n",
        "最好替换为之前的输出 ./output/chat_from_dialogue.jsonl"
      ],
      "metadata": {
        "id": "LXJz1nQ3ItMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python synthesis_chat.py -input ./data/Haruhi_first_merge_res.jsonl\\\n",
        "                         -output ./output/chat_augmented_by_foo.jsonl \\\n",
        "                         -method foo"
      ],
      "metadata": {
        "id": "a-GTiO1xIOie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chat2dialogue 通过inference引擎，将第一句话输入到里面去要出更多的对话\n",
        "#### - role_name 要和 src_reform/config.ini 中的角色名字一致\n",
        "#### - output_dialogue  是可选项，默认输出文件和 input_chat 在同一目录\n",
        "#### - other_names 可选"
      ],
      "metadata": {
        "id": "1ycjz0XmJZWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-Z2fFp\""
      ],
      "metadata": {
        "id": "bSfBcR28CH_M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python chat2dialogue.py -input_chat ./data/test_query_chat_Haruhi.jsonl\\\n",
        "                        -output_dialogue ./output/haruhi_output_dialogue.jsonl\\\n",
        "                        -role_name \"凉宫春日\" \\\n",
        "                        -other_names 凉宫 凉宫春日 春日"
      ],
      "metadata": {
        "id": "hdNTuVtzI2Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python chat2dialogue.py -input_chat ./data/test_query_chat_liyunlong.jsonl\\\n",
        "                        -output_dialogue ./output/liyunlong_output_dialogue.jsonl\\\n",
        "                        -role_name \"李云龙\""
      ],
      "metadata": {
        "id": "vvNqlIn3Jayo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python chat2dialogue.py -input_chat ./data/test_query_chat_weixiaobao.jsonl\\\n",
        "                        -output_dialogue ./output/weixiaobao_output_dialogue.jsonl\\\n",
        "                        -role_name \"韦小宝\""
      ],
      "metadata": {
        "id": "j0nGK0Z2MDTf",
        "outputId": "48b62ed9-404a-429e-8144-09408e1d1829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在下载Luotuo-Bert\n",
            "Downloading (…)lve/main/config.json: 100% 35.9k/35.9k [00:00<00:00, 118MB/s]\n",
            "Downloading (…)solve/main/models.py: 100% 21.1k/21.1k [00:00<00:00, 80.7MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/silk-road/luotuo-bert-medium:\n",
            "- models.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "Downloading pytorch_model.bin: 100% 1.31G/1.31G [00:05<00:00, 261MB/s]\n",
            "Luotuo-Bert下载完毕\n",
            "<bound method RawConfigParser.items of <configparser.ConfigParser object at 0x7cc86c1f7df0>>\n",
            "正在下载Luotuo-Bert\n",
            "Luotuo-Bert下载完毕\n",
            "Generating dialogue...\n",
            "创建临时文件夹output_韦小宝\n",
            "  0% 0/10 [00:00<?, ?it/s]\n",
            "Downloading (…)okenizer_config.json: 100% 394/394 [00:00<00:00, 1.86MB/s]\n",
            "\n",
            "Downloading (…)solve/main/vocab.txt: 100% 110k/110k [00:00<00:00, 1.81MB/s]\n",
            "\n",
            "Downloading (…)/main/tokenizer.json:   0% 0.00/439k [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)/main/tokenizer.json: 100% 439k/439k [00:00<00:00, 3.43MB/s]\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 125/125 [00:00<00:00, 726kB/s]\n",
            "100% 10/10 [00:42<00:00,  4.27s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "PRQyssPWBmuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -f -r /content/Chat-Haruhi-Suzumiya/\n",
        "!git clone https://github.com/LC1332/Chat-Haruhi-Suzumiya\n",
        "%cd /content/Chat-Haruhi-Suzumiya/kyon_generator/\n"
      ],
      "metadata": {
        "id": "1Ed_3MHdYIFz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}