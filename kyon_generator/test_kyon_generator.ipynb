{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8OXRGFXu38DBDUS976RFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Chat-Haruhi-Suzumiya/blob/main/kyon_generator/test_kyon_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat凉宫春日 Chat-Haruhi-Suzumiya\n",
        "\n",
        "[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)]()\n",
        "[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)]()\n",
        "[![Huggingface Gradio](https://img.shields.io/static/v1?label=Demo&message=Huggingface%20Gradio&color=orange)](https://huggingface.co/spaces/silk-road/ChatHaruhi)\n",
        "\n",
        "\n",
        "本脚本是李鲁鲁开发的KyonGenerator的测试工具，后者由\n",
        "\n",
        "李鲁鲁，闫晨曦, 包同学, 睡觉鱼等共同开发\n",
        "\n",
        "---\n",
        "\n",
        "**Chat凉宫春日**是模仿凉宫春日等一系列动漫人物，使用近似语气、个性和剧情聊天的语言模型，\n",
        "\n",
        "<details>\n",
        "  <summary> 本项目由李鲁鲁，冷子昂，闫晨曦，封小洋，scixing，沈骏一，Aria Fei, 米唯实, 吴平宇, 贾曜恺等开发。 </summary>\n",
        "\n",
        "李鲁鲁发起了项目，并完成了最早的版本，在多个微信群实现了测试。完成了训练数据自动生成对话部分，设计了整体的路线，并撰写报告。\n",
        "\n",
        "冷子昂负责了每一个阶段的Gradio开发，以及每个部分的功能整合和架构设计。\n",
        "\n",
        "闫晨曦一开始将李鲁鲁的notebook重构为app.py，参与了WebUI的embedding部分重构整合。\n",
        "\n",
        "封小洋进行了中文转日文模型的选型，完成了针对台词抽取图片的工具。整合了声纹识别。即将继续参加台本工具的开发。\n",
        "\n",
        "scixing实践了VITS语音，完成了台词对应的语音抽取，实现了第一个版本的声纹分类。\n",
        "\n",
        "沈骏一实现了使用ChatGLM2 finetune实验\n",
        "\n",
        "Aria(Yaying Fei)对接了whisper到台本工具。即将继续参加台本工具的开发。\n",
        "\n",
        "米唯实实现了Chat哆啦A梦的分支版本\n",
        "\n",
        "吴平宇部署了ChatGLM2的训练程序，并提供了训练的计算资源。\n",
        "\n",
        "贾曜恺开发了一个Vue前端实现方案\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "xQqfMSu5FwUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LC1332/Chat-Haruhi-Suzumiya"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iATX-_amFs0n",
        "outputId": "df69053f-c9aa-4951-9831-95becb8ca749"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Chat-Haruhi-Suzumiya'...\n",
            "remote: Enumerating objects: 5240, done.\u001b[K\n",
            "remote: Counting objects: 100% (1543/1543), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1161/1161), done.\u001b[K\n",
            "remote: Total 5240 (delta 389), reused 1494 (delta 369), pack-reused 3697\u001b[K\n",
            "Receiving objects: 100% (5240/5240), 103.28 MiB | 17.30 MiB/s, done.\n",
            "Resolving deltas: 100% (1817/1817), done.\n",
            "Updating files: 100% (2211/2211), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SytUs-oI4Hd",
        "outputId": "c6f1173f-6139-4840-9e35-7f55185b5b7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWCXGjG-FJdq",
        "outputId": "f2e20bd8-6fe6-4ae3-9faf-057122570370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Chat-Haruhi-Suzumiya/kyon_generator\n",
            "chat2dialogue.py\t   data\t\t\t  story2chat.py\n",
            "ChatGPT_for_generation.py  dialogue2chat.py\t  synthesis_chat_method_foo.py\n",
            "chatlog2dialogue.ipynb\t   dialogue2embedding.py  synthesis_chat.py\n",
            "chatlog2dialogue.py\t   dialogue2jsonl.py\t  train.py\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Chat-Haruhi-Suzumiya/kyon_generator/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZVbJHRUGhTK",
        "outputId": "d13255f0-cf63-4e88-e7ee-1205789f1b44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Haruhi-ContinuousGenerate_Dialogues.jsonl  Haruhi-Lulu_Dialogues.jsonl\n",
            "Haruhi_first_merge_res.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output"
      ],
      "metadata": {
        "id": "nTgRVhgcG39G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gradio前端记录的历史数据到dialogue数据\n",
        "chatlog2dialogue.py gradio前端记录的历史数据到dialogue数据的转化\n",
        "\n"
      ],
      "metadata": {
        "id": "QkKog1XUGdEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python chatlog2dialogue.py -input ./data/Haruhi-Lulu_Dialogues.jsonl\\\n",
        "                           -output ./output/Haruhi_Dialogues_from_history.jsonl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZmmLHFGGUgZ",
        "outputId": "83455bf8-d2e9-4d17-da9d-d4ad5a334cc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## story2chat 台本数据到一句话数据的转换\n",
        "\n",
        "Haruhi为例的话语料在\n",
        "\n",
        "/content/Chat-Haruhi-Suzumiya/characters/haruhi/texts"
      ],
      "metadata": {
        "id": "rTAg037YHTf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python story2chat.py -story_folder \"/content/Chat-Haruhi-Suzumiya/characters/haruhi/texts\" \\\n",
        "                     -output ./output/chat_from_story.jsonl \\\n",
        "                     -role \"春日\" \\\n",
        "                     -other_names 凉宫 凉宫春日"
      ],
      "metadata": {
        "id": "tJq8CswXHMar"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dialogue2chat 将连续对话批量抽取为一句话"
      ],
      "metadata": {
        "id": "fkuR83edH7am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python dialogue2chat.py -input ./data/Haruhi-Lulu_Dialogues.jsonl\\\n",
        "                     -output ./output/chat_from_dialogue.jsonl\\\n",
        "                     -role \"春日\"\\\n",
        "                     -other_names 凉宫 凉宫春日"
      ],
      "metadata": {
        "id": "zwZgBFPxH8dE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## synthesis_chats 将一些第一句话的文件，增广为更多的第一句话"
      ],
      "metadata": {
        "id": "y6ykfthzIfOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里需要设置OpenAI Key"
      ],
      "metadata": {
        "id": "MZApS5ubJE-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-KP8Zco\""
      ],
      "metadata": {
        "id": "o7oDiePZJfwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: 这里Haruhi_first_merge_res.jsonl本来就是synthesized的，\n",
        "\n",
        "最好替换为之前的输出 ./output/chat_from_dialogue.jsonl"
      ],
      "metadata": {
        "id": "LXJz1nQ3ItMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python synthesis_chat.py -input ./data/Haruhi_first_merge_res.jsonl\\\n",
        "                         -output ./output/chat_augmented_by_foo.jsonl \\\n",
        "                         -method foo"
      ],
      "metadata": {
        "id": "a-GTiO1xIOie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chat2dialogue 通过inference引擎，将第一句话输入到里面去要出更多的对话"
      ],
      "metadata": {
        "id": "1ycjz0XmJZWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python chat2dialogue.py -input_chat ./data/Haruhi_first_merge_res.jsonl\\\n",
        "                        -output_dialogue ./output/synthesized_dialogue.jsonl \\\n",
        "                        -config config.ini \\\n",
        "                        -role_name \"春日\"\\\n",
        "                        -other_names 凉宫 凉宫春日"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdNTuVtzI2Xu",
        "outputId": "4bc87d90-3dc5-4af3-ebdc-0666d08f1f86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/Chat-Haruhi-Suzumiya/kyon_generator/chat2dialogue.py\", line 18, in <module>\n",
            "    from ChatGPT_for_generation import ChatGPT\n",
            "  File \"/content/Chat-Haruhi-Suzumiya/kyon_generator/ChatGPT_for_generation.py\", line 11, in <module>\n",
            "    import utils\n",
            "ModuleNotFoundError: No module named 'utils'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vu1qVfdtJ0xM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}