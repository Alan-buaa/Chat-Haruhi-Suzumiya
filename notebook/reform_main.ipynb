{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Chat-Haruhi-Suzumiya/blob/main/notebook/reform_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat凉宫春日 Chat-Haruhi-Suzumiya\n",
        "\n",
        "[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)]()\n",
        "[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)]()\n",
        "[![Huggingface Gradio](https://img.shields.io/static/v1?label=Demo&message=Huggingface%20Gradio&color=orange)](https://huggingface.co/spaces/silk-road/ChatHaruhi)\n",
        "\n",
        "**Chat凉宫春日**是模仿凉宫春日等一系列动漫人物，使用近似语气、个性和剧情聊天的语言模型，\n",
        "\n",
        "<details>\n",
        "  <summary> 本项目由李鲁鲁，冷子昂，闫晨曦，封小洋，scixing，沈骏一，Aria Fei, 米唯实, 吴平宇, 贾曜恺等开发。 </summary>\n",
        "\n",
        "李鲁鲁发起了项目，并完成了最早的版本，在多个微信群实现了测试。完成了训练数据自动生成对话部分，设计了整体的路线，并撰写报告。\n",
        "\n",
        "冷子昂负责了每一个阶段的Gradio开发，以及每个部分的功能整合和架构设计。\n",
        "\n",
        "闫晨曦一开始将李鲁鲁的notebook重构为app.py，参与了WebUI的embedding部分重构整合。\n",
        "\n",
        "封小洋进行了中文转日文模型的选型，完成了针对台词抽取图片的工具。整合了声纹识别。即将继续参加台本工具的开发。\n",
        "\n",
        "scixing实践了VITS语音，完成了台词对应的语音抽取，实现了第一个版本的声纹分类。\n",
        "\n",
        "沈骏一实现了使用ChatGLM2 finetune实验\n",
        "\n",
        "Aria(Yaying Fei)对接了whisper到台本工具。即将继续参加台本工具的开发。\n",
        "\n",
        "米唯实实现了Chat哆啦A梦的分支版本\n",
        "\n",
        "吴平宇部署了ChatGLM2的训练程序，并提供了训练的计算资源。\n",
        "\n",
        "贾曜恺开发了一个Vue前端实现方案\n",
        "\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "gOJkH-EiXP0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这个脚本可以直接运行多人物角色的gradio客户端\n",
        "\n",
        "\n",
        "**TODO 现在需要在clone项目之后在.ini文件修改key才能运行**\n",
        "\n",
        "**需要冷子昂和闫晨曦fix，在colab进行设置**"
      ],
      "metadata": {
        "id": "lUb8Izg2XRSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers gradio openai tiktoken langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPPgMED8WhVF",
        "outputId": "f443df1a-b81d-464d-aa08-adf98b6d0e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDO1lO-MWZ9A",
        "outputId": "727833cd-6831-4bca-89e5-ce2399c0813f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Chat-Haruhi-Suzumiya'...\n",
            "remote: Enumerating objects: 3728, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 3728 (delta 6), reused 10 (delta 6), pack-reused 3697\u001b[K\n",
            "Receiving objects: 100% (3728/3728), 91.47 MiB | 35.70 MiB/s, done.\n",
            "Resolving deltas: 100% (1434/1434), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LC1332/Chat-Haruhi-Suzumiya.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Chat-Haruhi-Suzumiya/src_reform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0eATbMrWfYe",
        "outputId": "38b23dd7-824f-4443-da18-8862e390ca49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Chat-Haruhi-Suzumiya/src_reform\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gradioServer.py -key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY4j7sMxWtHM",
        "outputId": "ec9fbf35-4772-4c6b-e06d-1f6d276534b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "载入默认角色\n",
            "正在加载: DEFAULT 角色\n",
            "配置文件载入完成\n",
            "已找到角色文件夹\n",
            "选择使用GPT作为语言模型\n",
            "正在载入角色GPT所需资源\n",
            "正在下载Luotuo-Bert\n",
            "Downloading (…)lve/main/config.json: 100% 966/966 [00:00<00:00, 6.87MB/s]\n",
            "Downloading (…)solve/main/models.py: 100% 21.1k/21.1k [00:00<00:00, 70.1MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/silk-road/luotuo-bert:\n",
            "- models.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "Downloading pytorch_model.bin: 100% 414M/414M [00:17<00:00, 23.7MB/s]\n",
            "Luotuo-Bert下载完毕\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d5602d212599de6834.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "history is here :  []\n",
            "正在获取GPT回复\n",
            "history done\n",
            "Downloading (…)okenizer_config.json: 100% 539/539 [00:00<00:00, 2.58MB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 110k/110k [00:00<00:00, 30.5MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 439k/439k [00:00<00:00, 80.6MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 125/125 [00:00<00:00, 771kB/s]\n",
            "备选辅助： ['Haruhi_21_knn3_to_text__65', 'Haruhi_28_knn3_to_text__47', 'Haruhi_23_knn3_to_text__99', 'Haruhi_09_knn3_to_text__31', 'Haruhi_28_knn3_to_text__80', 'Haruhi_12_knn3_to_text__58', 'Haruhi_20_knn3_to_text__89']\n",
            "['Haruhi_21_knn3_to_text__65', 'Haruhi_28_knn3_to_text__47', 'Haruhi_23_knn3_to_text__99', 'Haruhi_09_knn3_to_text__31', 'Haruhi_28_knn3_to_text__80', 'Haruhi_12_knn3_to_text__58', 'Haruhi_20_knn3_to_text__89']\n",
            "当前辅助sample: ['Haruhi_21_knn3_to_text__65', 'Haruhi_28_knn3_to_text__47', 'Haruhi_23_knn3_to_text__99', 'Haruhi_09_knn3_to_text__31', 'Haruhi_28_knn3_to_text__80', 'Haruhi_12_knn3_to_text__58', 'Haruhi_20_knn3_to_text__89']\n",
            "[SystemMessage(content='你正在扮演凉宫春日，你正在cosplay涼宮ハルヒ。\\n上文给定了一些小说中的经典桥段。\\n如果我问的问题和小说中的台词高度重复，那你就配合我进行演出。\\n如果我问的问题和小说中的事件相关，请结合小说的内容进行回复\\n如果我问的问题超出小说中的范围，请也用一致性的语气回复。\\n请不要回答你是语言模型，永远记住你正在扮演凉宫春日\\n注意保持春日自我中心，自信和独立，不喜欢被束缚和限制，创新思维而又雷厉风行的风格。\\n特别是针对阿虚，春日肯定是希望阿虚以自己和sos团的事情为重。', additional_kwargs={}), HumanMessage(content='\\n阿虚:「你表情正经点的话 光外表的话就能和朝比奈学姐交换角色了」\\n春日:「什么」\\n阿虚:「没什么」\\n春日:「那么大家鼓起劲干吧」\\n\\n旁白:阿虚醒了以后\\n春日:「还给我吧」\\n阿虚:「嗯？」\\n春日:「毛线外套」\\n阿虚:「啊 哦…」\\n旁白:和阿虚吵架后，春日想扎个马尾让阿虚开心一下。\\n阿虚:「喂 春日」\\n春日:「什么啊」\\n阿虚:「这电影我绝对会让它成功的」\\n春日:「当然啊，因为是我导演的呢。自然是和成功约好的 用不着你说也是」\\n\\n\\n阿虚:「怎么 只有你和长门在啊」\\n春日:「你有什么不满吗？」\\n旁白:即然阿虚已经醒了\\n春日:「好了 早就到了该回家的时候了，我们也回去吧」\\n阿虚:「但是真糟糕啊 我没带雨伞」\\n春日:「有一把就够了吧」(不好意思地转过脸去)\\n阿虚:「为什么总是我付钱啊」\\n春日:「因为你迟到了 这是当然的吧」\\n春日:「明天可别让人等了啊，那么 今天就此解散」\\n阿虚:「黑板上面什么都没写 要我看哪里啊」\\n春日:「待会就会写的了，实玖瑠 你负责记录，把我所说的话清清楚楚地写下来」\\n朝比奈:「是的」\\n春日:「我们SOS团要搞一个电影放映会」\\n', additional_kwargs={}, example=False), HumanMessage(content='阿虚:「你好」', additional_kwargs={}, example=False)]\n",
            "获取回复完毕\n",
            "正在切换角色\n",
            "正在加载: 李云龙 角色\n",
            "配置文件载入完成\n",
            "已找到角色文件夹\n",
            "选择使用GPT作为语言模型\n",
            "正在载入角色GPT所需资源\n",
            "正在下载Luotuo-Bert\n",
            "Luotuo-Bert下载完毕\n",
            "角色切换完成\n",
            "history is here :  []\n",
            "正在获取GPT回复\n",
            "history done\n",
            "备选辅助： ['21', '9', '24', '25', '1', '10', '14']\n",
            "['21', '9', '24', '25', '1', '10', '14']\n",
            "当前辅助sample: ['21', '9', '24', '25']\n",
            "[SystemMessage(content='你正在扮演李云龙\\n上文给定了一些小说中的经典桥段。\\n如果我问的问题和小说中的台词高度重复，那你就配合我进行演出。\\n如果我问的问题和小说中的事件相关，请结合小说的内容进行回复\\n如果我问的问题超出小说中的范围，请也用一致性的语气回复。\\n请不要回答你是语言模型，永远记住你正在扮演李云龙\\n注意李云龙是一个非常喜欢说脏话，对日本和侵略者憎恨的人\\n李云龙的口头禅是“他娘的”，你要时不时的说出这句话\\n注意李云龙的语言是比较粗俗的，他没有读过书，不能表达的过于书面\\n李云龙的表达是非常具有中国特色的，要注意不能表达的像西方人', additional_kwargs={}), HumanMessage(content='\\n刑副团长:「带多少人来了」\\n张大彪:「不好意思，只有两千多人」\\n刑副团长:「我乖乖，你看你们这些人，平时让你们报编制，一个个都藏着掖着，现在可好，家庭都抖出来了吗，不像话，太不像话了」\\n李云龙:「找什么呢，团长，团长」\\n刑副团长:「团长，你都快当师长了」\\n李云龙:「这么多人，啥时候钻出这么多人」\\n刑副团长:「你还是问他们自己吧」\\n张大彪:「这还不算配合，咱们的当地武装所有夹下来，有上万人吧」\\n李云龙:「看来你们身子骨都硬了，一个个的都成了土财主了，老天给了我这个机会，让我指挥上万人作战，我谢谢你们了，我带我老婆，带赵政委，带赵家瑜死难的乡亲，谢谢你们了」\\n\\n张大彪:「报告。」\\n李云龙:「进来，大彪。」\\n张大彪:「哎。」\\n李云龙:「伤怎么样啦。」\\n张大彪:「没事了，鬼子的三八大盖穿透力强，可杀伤力倒不大，子弹在腿长留了个小眼儿。」\\n李云龙:「来闹两口，咋心眼那么实呢都给我喝了。」\\n张大彪:「团长您不总教育我们做人要实在吗。」\\n李云龙:「那你也不能太实在，你听不出来哪是客气话啊。」\\n张大彪:「团长我脑子笨。」\\n李云龙:「你别给我揣着明白装糊涂，要说你的表现不错是该赏你两口，等等，话还没说完呢你急什么，见了酒你就急没出息，你们一营这次仗打得不错，我正想向上级请示给你们闹个什么嘉奖什么的，来喝两口。」\\n\\n刑副团长:「团长，向师父和总部报告下，他说了一句话，总说这是史无前例的大仗了」\\n李云龙:「这是你的事，你听好了，独立团现在就交给你，我李云龙擅自行动的罪责难逃，只是有一条，你别把独立团给赖垮了，现在可是兵强马壮的时候」\\n李云龙:「走」\\n旅长陈庚:「讲啊，为什么不讲了，好好讲讲，你的英雄故事，讲吗？」\\n旅长陈庚:「怎么，怎么，不说话了，不讲啊，你不讲，我来跟你讲，做一名男人，你有种，有情有义，是条汉子，可做一名军人，你小子，根本就不够格」\\n李云龙:「我没不服气，谁不服气了，哪敢的」\\n旅长陈庚:「你还敢嘴硬，我现在撤进去」\\n李云龙:「我早就把自己给革职了」\\n旅长陈庚:「好，好，我叫你无关一身清，炊事班长，有」\\n旅长陈庚:「去，把你行军的大锅背过来」\\n', additional_kwargs={}, example=False), HumanMessage(content='张大彪:「团长，我来了」', additional_kwargs={}, example=False)]\n",
            "获取回复完毕\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3IHZldXQWwOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}